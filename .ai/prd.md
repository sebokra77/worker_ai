rojektu

**AI Worker** to niezale≈ºna us≈Çuga backendowa odpowiedzialna za realizacjƒô logiki biznesowej systemu korekty i t≈Çumacze≈Ñ tekst√≥w.  

Jej g≈Ç√≥wnym zadaniem jest **automatyczne przetwarzanie danych tekstowych** zapisanych w lokalnej bazie, poprzez po≈ÇƒÖczenie z modelem sztucznej inteligencji (np. **Gemini API** lub **GPT-5**) i zapisanie wynik√≥w w bazie danych.

Worker wywo≈Çywany w CLI za pomoc cron lub z aplikacji www.

---
## Zakres funkcjonalny

Us≈Çuga odpowiada za:

1. Pobieranie zada≈Ñ (`task`) i element√≥w (`task_item`) ze statusem ‚Äûdo przetworzenia‚Äù.
2. Komunikacjƒô z wybranym modelem AI poprzez API.
3. Przetwarzanie tekstu (np. korekta, t≈Çumaczenie, analiza).
4. Zapis wynik√≥w i aktualizacjƒô status√≥w w bazie.
5. Obs≈Çugƒô b≈Çƒôd√≥w, raportowanie i logowanie postƒôpu.

Ca≈Çy proces jest w pe≈Çni odseparowany od interfejsu webowego (Yii2), co zapewnia bezpiecze≈Ñstwo i skalowalno≈õƒá systemu.

Procesy uruchamiane przez cron lun na ≈ºƒÖdanie u≈ºytkownika

Wymagania projektu :
- nie u≈ºywaj  sqlalchemy szybkie zapytania SQL jawne zgodne z MySQL
- **czysty MySQL (PyMySQL)** - bez SQLAlchemy
- zrobiƒá w≈ÇasnƒÖ prostƒÖ klasƒô do MySQL (po≈ÇƒÖcznie init, query, execute, close)
- gotowy do uruchomienia z CMD lub PowerShell jako CLI
- `CLI` z parametrami `--task`, `--task-item`, `--max-item`, `--dry-run`
- `FastAPI` z endpointem `/task/run`
- plik `.env` z konfiguracjƒÖ MySQL i innymi stalymi
- przygotowany pod przysz≈Çe kolejki Celery,  
- z pe≈ÇnƒÖ strukturƒÖ i zawarto≈õciƒÖ plik√≥w.
- `requirements.txt`, `README.txt` (dla Windows) i `DB_Description.txt`.

Przyk≈Çad
```
import pymysql
from app.config import settings

class MySQLDatabase:
    """Prosty klient MySQL bez ORM, tylko czyste SQL."""
    def __init__(self):
        self.conn = pymysql.connect(
            host='localhost',
            user='root',
            password='root',
            database='ai_worker',
            charset='utf8mb4',
            cursorclass=pymysql.cursors.DictCursor
        )

    def query(self, sql: str, params: tuple = ()):
        """Wykonuje zapytanie SELECT i zwraca wynik jako listƒô s≈Çownik√≥w."""
        with self.conn.cursor() as cursor:
            cursor.execute(sql, params)
            return cursor.fetchall()

    def execute(self, sql: str, params: tuple = ()):
        """Wykonuje INSERT/UPDATE/DELETE i zatwierdza transakcjƒô."""
        with self.conn.cursor() as cursor:
            cursor.execute(sql, params)
        self.conn.commit()

    def close(self):
        self.conn.close()
```

---
## Parametry uruchomienia skryptu

| Parametr      | Opis                                          | Przyk≈Çad                            |
| ------------- | --------------------------------------------- | ----------------------------------- |
| `--task`      | ID zadania (`id_task`)                        | `python worker.py --task 42`        |
| `--task-item` | ID pojedynczego rekordu (`id_task_item`)      | `python worker.py --task-item 1005` |
| `--max-item`  | Maksymalna liczba zada≈Ñ przetwarzanych item√≥w | `--max-task 10`                     |
| `--dry-run`   | Tryb testowy bez zapisu do bazy               | `--dry-run`                         |

Je≈õli nie podano parametr√≥w, `--task-item` automatycznie pobiera **najstarsze aktywne zadania** (`status_id = 0`) i przetwarza je do wyczerpania limitu. Je≈ºeli podano `--task` pobiera najstarsze task_item dla danego task.


## Zalecany podzia≈Ç aplikacji 

Zalecany podzia≈Ç aplikacji  CLI + FastAPI, gotowy pod przysz≈Çe kolejki (nie oprogramowuj routera na razie zostaw strukturƒô pod przysz≈Çy rozw√≥j)

```
ai_worker/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ router.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes_task.py
‚îÇ   ‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îú‚îÄ‚îÄ ai/
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ cli/
‚îÇ   ‚îî‚îÄ‚îÄ worker_cli.py
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ README.txt
‚îî‚îÄ‚îÄ DB_Description.txt
```

Przep≈Çyw aplikacji :
main.py ‚Üí worker.py ‚Üí repository.py ‚Üí ai.client.py ‚Üí models.py

---

## Przep≈Çyw procesu przetwarzania

1. üü¢ **Pobranie zadania (`task`)**  
   - wybranie najstarszego najstarszego taska  statusem IN_PROGRESS lub NEW
   - pobrani danych modelu powiƒÖzanego z tasakiem
   - status zmienia siƒô z `0 = NEW` ‚Üí `1 = IN_PROGRESS`
   - konfiguracja polaczenia LLM (z tabeli `ai_model` na podstawie klucza `task.id_ai_model` ) w ramach modelu Gemmini

1. üß© **Budowa promptu**  
   - przyk≈Çad:   ‚ÄûPopraw b≈Çƒôdy ortograficzne i stylistyczne w poni≈ºszym tek≈õcie bez zmiany znaczenia.‚Äù Do tego bƒôdzie pobiera≈Ç opis danych do przetworzenia z pola `task.desctiption`
   
3. üì¶ **Pobranie rekord√≥w (`task_item`)**  
   - status: `0 = PENDING`  
   - pobierane porcjami, np. po 10 rekord√≥w (zgodnie z parametrami wywo≈Çania)

4. üåê **Wys≈Çanie do modelu AI (Gemini API)**  
   - u≈ºywany klucz z tabeli `ai_model.api_key_encrypted`

5. üì• **Odbi√≥r i zapis wyniku**  
   - `text_corrected` ‚Üí zapis poprawionej wersji  
   - `change_summary` ‚Üí opis zmian  
   - `tokens_input`, `tokens_output`
   - `status_id = 1 (PROCESSED)`

6. üóÉÔ∏è **Aktualizacja `task`**  
   - zwiƒôkszenie `records_processed`  
   - zapis `finished_at` po zako≈Ñczeniu


7. ‚úÖ **Zako≈Ñczenie**  
   - je≈õli wszystkie rekordy przetworzone ‚Üí `status_id = 2 (COMPLETED)`  
   - w przypadku b≈Çƒôdu ‚Üí `status_id = 3 (ERROR)`


### Sekcje ‚ÄûSubprocesy‚Äù / Podzadania

Dodaj opis **mikrozada≈Ñ (subtasks)**, kt√≥re ClauCode mo≈ºe przekszta≈Çciƒá w funkcje lub modu≈Çy:

| Nazwa podzadania            | Zakres                      | Funkcja docelowa / Modu≈Ç                  |
| --------------------------- | --------------------------- | ----------------------------------------- |
| `fetch_task()`              | Pobranie najstarszego taska | `db.task_repository.get_next()`           |
| `fetch_items(task_id)`      | Pobranie rekord√≥w           | `db.task_item_repository.list_pending()`  |
| `build_prompt(task)`        | Zbudowanie promptu          | `ai.prompt_builder.build(task)`           |
| `send_to_ai(model, text)`   | Wywo≈Çanie API               | `ai.client.send()`                        |
| `save_result(item, result)` | Zapis wyniku do DB          | `db.task_item_repository.update_result()` |
| `update_task_status(task)`  | Uaktualnienie postƒôpu       | `db.task_repository.update_progress()`    |


---
### Sekcje ‚ÄûSubprocesy‚Äù / Podzadania

Dodaj opis **mikrozada≈Ñ (subtasks)**, kt√≥re ClauCode mo≈ºe przekszta≈Çciƒá w funkcje lub modu≈Çy:

|Nazwa podzadania|Zakres|Funkcja docelowa / Modu≈Ç|
|---|---|---|
|`fetch_task()`|Pobranie najstarszego taska|`db.task_repository.get_next()`|
|`fetch_items(task_id)`|Pobranie rekord√≥w|`db.task_item_repository.list_pending()`|
|`build_prompt(task)`|Zbudowanie promptu|`ai.prompt_builder.build(task)`|
|`send_to_ai(model, text)`|Wywo≈Çanie API|`ai.client.send()`|
|`save_result(item, result)`|Zapis wyniku do DB|`db.task_item_repository.update_result()`|
|`update_task_status(task)`|Uaktualnienie postƒôpu|`db.task_repository.update_progress()`|

---

## Struktura tabel (fragment DDL)

Plik [[DB tablice s≈Çownikowe]]

---

## Architektura techniczna

| Komponent         | Technologia                     | Opis                                           |
| ----------------- | ------------------------------- | ---------------------------------------------- |
| API serwisowe     | **FastAPI**                     | REST API do uruchamiania i monitorowania zada≈Ñ |
| ~~Kolejka zada≈Ñ~~ | ~~**Celery + Redis/RabbitMQ**~~ | ~~Asynchroniczne przetwarzanie rekord√≥w~~      |
| Warstwa AI        | Gemini 2.5 Pro                  | Korekta, t≈Çumaczenie lub analiza tekstu        |
| ORM / DB          | **SQLAlchemy + PyMySQL**        | Obs≈Çuga bazy lokalnej (`task`, `task_item`)    |
| Logowanie         | **Celery Flower / Prometheus**  | Monitoring postƒôpu i stanu zada≈Ñ               |

---

## Wydajno≈õƒá i optymalizacja

- Statusy przechowywane jako liczby (`TINYINT`) ‚Üí szybkie filtrowanie i indeksowanie.  
- Obs≈Çuga b≈Çƒôd√≥w i ponownych pr√≥b (`retry`) w przypadku timeout√≥w.

---

## Przep≈Çyw danych (diagram)

```mermaid
flowchart TD
A["Pobierz task (status_id=0)"] --> B["Zmie≈Ñ status_id ‚Üí 1 (IN_PROGRESS)"]
B --> C["Pobierz task_item (status_id=0)"]
C --> D["Zbuduj prompt i wy≈õlij do AI (Gemini API)"]
D --> E["Odbierz wynik i zapisz text_corrected"]
E --> F["Aktualizuj status_id ‚Üí 1 (PROCESSED)"]
F --> G{"Wszystkie rekordy przetworzone?"}
G -->|Tak| H["Zmie≈Ñ task.status_id ‚Üí 2 (COMPLETED)"]
G -->|Nie| C
```

---

## 0Ô∏è‚É£ Bezpiecze≈Ñstwo

- Klucze API i dane logowania szyfrowane (`AES_ENCRYPT`, `VARBINARY`).
- Dane ≈∫r√≥d≈Çowe nie sƒÖ modyfikowane ‚Äî przetwarzanie odbywa siƒô tylko na lokalnych kopiach.
- Ka≈ºda operacja ma w≈Çasny identyfikator (`operation_uuid`).
- Dane osobowe nigdy nie sƒÖ przekazywane do modelu AI.

---

## 1Ô∏è‚É£ Przyk≈Çadowe logi przetwarzania

| Etap | Log systemowy |
|------|----------------|
| START | `[Task 42] Rozpoczƒôto przetwarzanie (15 rekord√≥w)` |
| FETCH | `[Task 42] Pobrano 10 rekord√≥w ze statusem 0 (pending)` |
| PROMPT | `[Gemini] Wys≈Çano prompt: 280 znak√≥w` |
| RESULT | `[TaskItem 1005] Otrzymano wynik, zapisano text_corrected` |
| DONE | `[Task 42] Przetwarzanie zako≈Ñczone ‚Äì 10/10 rekord√≥w` |
| ERROR | `[Task 42] B≈ÇƒÖd API: Timeout` |

---

## 2Ô∏è‚É£ Wyniki i integracja z frontendem

Po zako≈Ñczeniu dzia≈Çania workera:
- wyniki sƒÖ widoczne w panelu Yii2 (modu≈Ç `task_item`),
- u≈ºytkownik mo≈ºe zatwierdzaƒá (`accepted`) lub odrzucaƒá (`rejected`) wyniki,
- po zatwierdzeniu rekord√≥w sƒÖ eksportowane z powrotem do bazy ≈∫r√≥d≈Çowej (`UPDATE`).

---

## 3Ô∏è‚É£ Podsumowanie

**AI Worker** to kluczowy komponent systemu do automatycznej korekty i t≈Çumaczenia tekst√≥w.  
Zapewnia:
- bezpieczne przetwarzanie w tle,  
- pe≈ÇnƒÖ kontrolƒô nad procesem,  
- wysokƒÖ wydajno≈õƒá dziƒôki statusom liczbowym i indeksowaniu,  
- ≈ÇatwƒÖ integracjƒô z frontendem i bazƒÖ danych.  

Dziƒôki architekturze **FastAPI + Celery + Redis** mo≈ºliwe jest skalowanie systemu i r√≥wnoleg≈Ça obs≈Çuga tysiƒôcy rekord√≥w w jednym cyklu.

### Funcjonalno≈õci nie objete MVP:
- Worker docelowo bƒôdzie dzia≈Ça≈Ç **asynchronicznie** i **r√≥wnolegle** ‚Äì mo≈ºe obs≈Çugiwaƒá wiele zada≈Ñ jednocze≈õnie, dziƒôki architekturze **FastAPI + Celery + Redis/RabbitMQ**.
- brak szyfrowania kluczy API dla modeli LLM 